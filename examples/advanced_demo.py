"""
Neural Dust Network - Complete Demonstration
The "One-Evening Hack to Impress Investors" Demo

Shows multiple simulated devices learning collaboratively to classify MNIST digits
without ever sharing raw data - only sharing learned knowledge.
"""

import time
import threading
import numpy as np
import torch
import matplotlib.pyplot as plt
from neural_dust.dust_model import create_dust_model, get_mnist_data, train_dust_model, test_dust_model
from neural_dust.dust_gossip import DustGossip
from neural_dust.dust_federated import FederatedDustNode, DustSwarm
from neural_dust.dust_security import DustSecurity, SecureDustGossip
import warnings
warnings.filterwarnings('ignore')

class DustNetworkDemo:
    """
    Orchestrates the complete Neural Dust Network demonstration.
    """
    
    def __init__(self, num_devices=3, secure_mode=True):
        self.num_devices = num_devices
        self.secure_mode = secure_mode
        self.devices = []
        self.results = {}
        
        print("=" * 60)
        print("üåü NEURAL DUST NETWORK - LIVE DEMONSTRATION üåü")
        print("=" * 60)
        print(f"Setting up {num_devices} simulated devices...")
        print(f"Security mode: {'ENABLED' if secure_mode else 'DISABLED'}")
        print()
    
    def setup_devices(self):
        """Initialize all devices in the network"""
        base_port = 55000
        
        for i in range(self.num_devices):
            device_id = f"device_{i:02d}"
            
            # Create device components
            device = {
                'id': device_id,
                'port': base_port + i,
                'model': create_dust_model(),
                'gossip': DustGossip(port=base_port + i, node_id=device_id),
                'accuracy_history': [],
                'learning_active': False
            }
            
            if self.secure_mode:
                device['security'] = DustSecurity(device_id)
                device['secure_gossip'] = SecureDustGossip(
                    device['gossip'], 
                    device['security']
                )
            
            self.devices.append(device)
            print(f"‚úì {device_id} initialized (port {device['port']})")
        
        # Establish trust relationships in secure mode
        if self.secure_mode:
            self._establish_trust_network()
        
        print(f"\nüîó Neural Dust Network ready with {len(self.devices)} devices!\n")
    
    def _establish_trust_network(self):
        """Establish trust relationships between all devices"""
        print("\nüîê Establishing trust network...")
        
        for i, device_a in enumerate(self.devices):
            for j, device_b in enumerate(self.devices):
                if i != j:
                    # Get public key data
                    pub_data = device_b['security'].get_public_key_qr_data()
                    
                    # Add as trusted peer
                    device_a['security'].add_trusted_peer(
                        pub_data['node_id'],
                        pub_data['public_key'],
                        pub_data['fingerprint']
                    )
        
        print("‚úì All devices now trust each other")
    
    def test_initial_performance(self):
        """Test all devices with random weights"""
        print("üìä Testing initial performance (random weights)...")
        
        # Load test data
        _, test_loader = get_mnist_data(batch_size=1000)
        
        initial_accuracies = []
        for device in self.devices:
            loss, accuracy = test_dust_model(device['model'], test_loader)
            initial_accuracies.append(accuracy)
            device['accuracy_history'].append(accuracy)
            print(f"   {device['id']}: {accuracy:.1f}% accuracy")
        
        avg_accuracy = np.mean(initial_accuracies)
        print(f"\nüìà Average initial accuracy: {avg_accuracy:.1f}%")
        return avg_accuracy
    
    def simulate_individual_learning(self, rounds=3):
        """Simulate each device learning locally from different data"""
        print(f"\nüß† Phase 1: Individual Learning ({rounds} rounds)")
        print("Each device learns from its own local data (no sharing yet)...")
        
        # Load training data
        train_loader, test_loader = get_mnist_data(batch_size=64)
        
        for round_num in range(rounds):
            print(f"\n--- Round {round_num + 1} ---")
            
            for device in self.devices:
                # Train on a few batches
                train_dust_model(device['model'], train_loader, epochs=1)
                
                # Test performance
                loss, accuracy = test_dust_model(device['model'], test_loader)
                device['accuracy_history'].append(accuracy)
                print(f"   {device['id']}: {accuracy:.1f}% accuracy")
        
        # Show individual learning results
        final_accuracies = [device['accuracy_history'][-1] for device in self.devices]
        avg_accuracy = np.mean(final_accuracies)
        std_accuracy = np.std(final_accuracies)
        
        print(f"\nüìä After individual learning:")
        print(f"   Average accuracy: {avg_accuracy:.1f}%")
        print(f"   Standard deviation: {std_accuracy:.1f}%")
        print(f"   Range: {min(final_accuracies):.1f}% - {max(final_accuracies):.1f}%")
        
        return avg_accuracy
    
    def start_collaborative_learning(self):
        """Start the magical collaborative learning phase"""
        print("\nüåê Phase 2: Collaborative Learning")
        print("Devices now share knowledge (not data) through the Neural Dust Network...")
        
        # Start gossip protocols
        for device in self.devices:
            device['gossip'].start_listening()
            device['learning_active'] = True
        
        print("‚úì All devices now listening for knowledge updates")
        
        # Load training data
        train_loader, test_loader = get_mnist_data(batch_size=64)
        
        # Run collaborative learning for several iterations
        for iteration in range(5):
            print(f"\n--- Collaborative Iteration {iteration + 1} ---")
            
            # Each device does local training
            for device in self.devices:
                # Local training step
                train_dust_model(device['model'], train_loader, epochs=1)
                
                # Broadcast learned weights
                if self.secure_mode:
                    device['secure_gossip'].secure_broadcast_delta(
                        device['model'].state_dict(), 
                        epoch=iteration
                    )
                else:
                    device['gossip'].broadcast_delta(
                        device['model'].state_dict(), 
                        epoch=iteration
                    )
            
            # Allow time for gossip propagation
            time.sleep(1)
            
            # Each device merges received knowledge
            for device in self.devices:
                if self.secure_mode:
                    # Get verified deltas
                    verified_deltas = device['secure_gossip'].get_verified_deltas(max_count=3)
                    
                    if verified_deltas:
                        # Merge with our model
                        all_models = [delta[1] for delta in verified_deltas]
                        all_models.append(device['model'].state_dict())
                        
                        # Federated averaging
                        merged_state = self._federated_average(all_models)
                        device['model'].load_state_dict(merged_state)
                        
                        print(f"   {device['id']}: Merged knowledge from {len(verified_deltas)} peers")
                else:
                    # Simple averaging without security
                    deltas = device['gossip'].get_received_deltas(max_count=3)
                    if deltas:
                        all_models = [delta[1] for delta in deltas]
                        all_models.append(device['model'].state_dict())
                        
                        merged_state = self._federated_average(all_models)
                        device['model'].load_state_dict(merged_state)
                        
                        print(f"   {device['id']}: Merged knowledge from {len(deltas)} peers")
            
            # Test all devices
            accuracies = []
            for device in self.devices:
                loss, accuracy = test_dust_model(device['model'], test_loader)
                device['accuracy_history'].append(accuracy)
                accuracies.append(accuracy)
            
            avg_accuracy = np.mean(accuracies)
            std_accuracy = np.std(accuracies)
            
            print(f"   üìà Network average: {avg_accuracy:.1f}% (¬±{std_accuracy:.1f}%)")
            
            # Check for convergence
            if std_accuracy < 2.0:  # Devices are converging
                print("   üéØ Network convergence detected!")
        
        return np.mean(accuracies)
    
    def _federated_average(self, state_dicts):
        """Perform federated averaging on model state dictionaries"""
        if not state_dicts:
            return {}
        
        averaged_state = {}
        first_state = state_dicts[0]
        
        for key in first_state.keys():
            averaged_state[key] = torch.zeros_like(first_state[key])
        
        # Sum all parameters
        for state_dict in state_dicts:
            for key in averaged_state.keys():
                if key in state_dict:
                    averaged_state[key] += state_dict[key]
        
        # Average by dividing by count
        num_models = len(state_dicts)
        for key in averaged_state.keys():
            averaged_state[key] = averaged_state[key] / num_models
        
        return averaged_state
    
    def show_final_results(self):
        """Display the impressive final results"""
        print("\n" + "=" * 60)
        print("üéâ NEURAL DUST NETWORK DEMONSTRATION COMPLETE! üéâ")
        print("=" * 60)
        
        # Calculate improvements
        initial_accuracy = self.devices[0]['accuracy_history'][0]
        final_accuracies = [device['accuracy_history'][-1] for device in self.devices]
        final_avg = np.mean(final_accuracies)
        improvement = final_avg - initial_accuracy
        
        print(f"\nüìä RESULTS SUMMARY:")
        print(f"   Initial accuracy (random): {initial_accuracy:.1f}%")
        print(f"   Final network accuracy: {final_avg:.1f}%")
        print(f"   Total improvement: +{improvement:.1f}%")
        print(f"   Network convergence: ¬±{np.std(final_accuracies):.1f}%")
        
        # Show individual device results
        print(f"\nüîß INDIVIDUAL DEVICE PERFORMANCE:")
        for device in self.devices:
            initial = device['accuracy_history'][0]
            final = device['accuracy_history'][-1]
            print(f"   {device['id']}: {initial:.1f}% ‚Üí {final:.1f}% (+{final-initial:.1f}%)")
        
        # Privacy guarantee
        print(f"\nüîí PRIVACY GUARANTEE:")
        print("   ‚úì No raw MNIST images were shared between devices")
        print("   ‚úì Only learned weight updates were exchanged")
        print("   ‚úì Each device keeps its training data private")
        
        if self.secure_mode:
            print("   ‚úì All knowledge updates cryptographically verified")
        
        # Technical stats
        print(f"\n‚ö° TECHNICAL STATS:")
        total_deltas = sum(device['gossip'].stats['deltas_sent'] for device in self.devices)
        total_bytes = sum(device['gossip'].stats['bytes_sent'] for device in self.devices)
        
        print(f"   Total knowledge updates: {total_deltas}")
        print(f"   Total bytes transmitted: {total_bytes:,}")
        print(f"   Average update size: {total_bytes//max(1,total_deltas):,} bytes")
        print(f"   Model size: ~27 KB per device")
        
        print(f"\nüåü This is the Neural Dust Network in action!")
        print("   - Tiny models (27 KB each)")
        print("   - Privacy-preserving learning")
        print("   - No central server required")
        print("   - Continuous improvement")
        
    def cleanup(self):
        """Clean up all resources"""
        for device in self.devices:
            device['gossip'].stop_listening()
            if 'security' in device:
                device['security']._cleanup_old_signatures()
        print("\nüßπ Cleanup complete")
    
    def run_full_demo(self):
        """Run the complete demonstration"""
        try:
            # Setup
            self.setup_devices()
            
            # Test initial performance
            initial_acc = self.test_initial_performance()
            
            # Individual learning phase
            individual_acc = self.simulate_individual_learning()
            
            # Collaborative learning phase
            collaborative_acc = self.start_collaborative_learning()
            
            # Show results
            self.show_final_results()
            
            return {
                'initial_accuracy': initial_acc,
                'individual_accuracy': individual_acc,
                'collaborative_accuracy': collaborative_acc,
                'improvement': collaborative_acc - initial_acc
            }
            
        finally:
            self.cleanup()

def quick_demo():
    """Run a quick 2-device demo"""
    print("üöÄ Running Quick Neural Dust Network Demo...")
    demo = DustNetworkDemo(num_devices=2, secure_mode=True)
    return demo.run_full_demo()

def full_demo():
    """Run the complete 3-device demo"""
    print("üöÄ Running Full Neural Dust Network Demo...")
    demo = DustNetworkDemo(num_devices=3, secure_mode=True)
    return demo.run_full_demo()

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "--quick":
        results = quick_demo()
    else:
        results = full_demo()
    
    print(f"\n‚ú® Demo completed with {results['improvement']:.1f}% improvement!")